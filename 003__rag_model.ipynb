{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb12bfc-4617-44a5-bc24-89e99db3d8d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LLMのRAGを使ったQABOT\n",
    "\n",
    "1. **データ取得**:\n",
    "    - ICML 2024の論文PDFを取得し、./icml_2024_papersディレクトリに格納する\n",
    "2. **データの埋め込みベクトル化**:\n",
    "    - 取得したPDFからテキストを抽出し、ベクトル化する。\n",
    "3. **LLMのRAGモデルの設定**:    <---- now\n",
    "    - 質問に対して関連する文書を検索し、その文書を基に回答を生成するRAGモデルを設定する。\n",
    "    1. 関連する文章自体の概要を出力する\n",
    "    \n",
    "4. **QABOTの構築**:\n",
    "    - ユーザーインターフェースを作成し、ユーザーからの質問に対してRAGモデルを使って回答するQABOTを構築する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff081a0e-a79b-4242-80a1-53353b359319",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai==1.3.4 in /usr/local/lib/python3.10/dist-packages (1.3.4)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.3.4) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.4) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.3.4) (1.2.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.4) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.4) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.4) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.3.4) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.3.4) (2.20.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv tiktoken\n",
    "!pip3 install openai==1.3.4\n",
    "!pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4251e4-d22d-4aae-8c78-c141e533e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect==1.0.9 in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from langdetect==1.0.9) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: lingua-language-detector==2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install langdetect==1.0.9\n",
    "!pip3 install lingua-language-detector==2.0.2\n",
    "!pip3 install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce94ef3-58d8-42c1-ab44-f369f3bc991d",
   "metadata": {},
   "source": [
    "## 質問に対して関連する文書を検索し、その文書を基に回答を生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b54e335-37e9-41c9-93f4-b2af4af9d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "from PyPDF2 import PdfReader\n",
    "from langdetect import detect\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead3561e-1213-4fb7-9311-dee1711699b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03cf434-ddb0-49bd-aff8-f8e19385638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "MODEL_NAME = \"gpt-3.5-turbo-0125\"\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "# MODEL_NAME = \"gpt-4-0125-preview\"\n",
    "# MODEL_NAME = \"gpt-4-turbo-2024-04-09\"\n",
    "MODEL4o_NAME = \"gpt-4o-2024-05-13\"\n",
    "\n",
    "# モデルとエンコーディングの設定\n",
    "# EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "embedding_encoding = \"cl100k_base\"\n",
    "# max_tokens = 8000\n",
    "\n",
    "max_tokens = 1000\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "# OpenAIクライアントの初期化\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00cbf282-879d-4cb6-a6ab-b076af33be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関連度を計算するための関数\n",
    "def relatedness_fn(x, y):\n",
    "    return 1 - spatial.distance.cosine(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d228fac-f26d-4f33-9a4c-848ad1bd7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search function\n",
    "def strings_ranked_by_relatedness(query: str, csv_files, top_n: int = 3):\n",
    "    related_texts = []\n",
    "    query_embedding_response = client.embeddings.create(model=EMBEDDING_MODEL, input=query)\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file, converters={'embedding': ast.literal_eval})\n",
    "\n",
    "        strings_and_relatednesses = [\n",
    "            (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]), csv_file)\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "        related_texts.extend(strings_and_relatednesses)\n",
    "\n",
    "    related_texts.sort(key=lambda x: x[1], reverse=True)\n",
    "    # print(related_texts[:2])\n",
    "    strings, relatednesses, files = zip(*related_texts[:top_n])\n",
    "    return strings, relatednesses, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e510f726-e9d3-4363-b5d1-6864ffbd452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-3.5で回答を生成\n",
    "def generate_response(query: str, csv_files, top_n=3):\n",
    "    strings, relatednesses, files = strings_ranked_by_relatedness(query, csv_files, top_n=top_n)\n",
    "    context = \"\\n\\n\".join([f\"File: {file}\\nText: {text}\" for text, file in zip(strings, files)])\n",
    "    prompt = [\n",
    "        {'role': 'system', 'content': 'You are an expert assistant who answers questions based on provided documents.'},\n",
    "        {'role': 'user', 'content': f\"Answer the following question based on the provided context.\\n\\nQuestion: {query}\\n\\nContext:\\n{context}\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=prompt,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    # 重複ファイル名削除チェック\n",
    "    used_files = set()\n",
    "    for file, text in zip(files, strings):\n",
    "        if file not in used_files:\n",
    "            # print(f\"File: {file}\")\n",
    "            used_files.add(file)\n",
    "    return response.choices[0].message.content, used_files, strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685ef367-1e33-405b-a1be-a33215f61880",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./icml_2024_embeddings\"\n",
    "csv_dir = save_dir\n",
    "# csv_files = os.listdir(save_dir)\n",
    "csv_files = [os.path.join(csv_dir, file) for file in os.listdir(csv_dir) if file.endswith('.csv')]\n",
    "# csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832d9423-a01c-4c6c-8293-8e1a8ad4b06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.5 s, sys: 289 ms, total: 30.8 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 質問に対する回答を生成\n",
    "query = \"RAGを使ったフレームワークやLLMオーケストレーションフレームワーク、Agentに関連する提案内容についてその技術的な内容を順番に過不足なく説明してください\"\n",
    "response, files, strings = generate_response(query, csv_files, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba0c543-5bae-43dc-9eda-ee5d253e993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: en\n"
     ]
    }
   ],
   "source": [
    "# linguaを使用するとmarkdown記法を英語と判断してしまうのでナイーブベースで言語取得\n",
    "lang = detect(response)\n",
    "print(f\"language: {lang}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2180d24f-e60c-472a-8a6b-1490e21fdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_japanese(model_name, detailed_outline):\n",
    "    \"\"\"\n",
    "    Translates the detailed outline of a Wikipedia page from English to Japanese.\n",
    "    \n",
    "    Parameters:\n",
    "    model_name (str): The model to be used for translation.\n",
    "    detailed_outline (str): The detailed outline in English.\n",
    "    \n",
    "    Returns:\n",
    "    str: The translated outline in Japanese.\n",
    "    \"\"\"\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You need to translate the following English text into Japanese.\"},\n",
    "        {\"role\": \"user\", \"content\": detailed_outline},\n",
    "        {\"role\": \"system\", \"content\": \"Please provide the translation of the entire text into Japanese, maintaining the accuracy and context of the original information.\"}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=prompt,\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    \n",
    "    translated_outline = response.choices[0].message.content\n",
    "    \n",
    "    return translated_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b55556-e666-4676-95fd-1527053c3c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.67 ms, sys: 0 ns, total: 8.67 ms\n",
      "Wall time: 8.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if lang != \"ja\":\n",
    "    translated_response = translate_to_japanese(MODEL_NAME, response)\n",
    "else:\n",
    "    translated_response = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5038dadb-16a4-4e97-9681-0eba7dc5fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: RAGフレームワーク、LLMオーケストレーションフレームワーク、およびエージェントに関連する提案に関連する技術内容を包括的に説明するためには、以下の文書で提示された順序に従うことができます：\n",
      "\n",
      "1. **RAGフレームワーク**:\n",
      "   - RAG（Retrieval-Augmented Generation）戦略は、現在の会話コンテキストに整合するダイアログ例を選択することを含みます。応答を生成するために追加の知識ベースを参照します。\n",
      "   - RAGのバリエーションには、構造化データソースなどの複雑なコンポーネントを組み込むために開発されたものがあります。たとえば、RET-LLMはパーソナライズされた知識グラフメモリを構築し、SUGREは知識グラフから関連するサブグラフを埋め込むためにGraph Neural Networksを使用します。\n",
      "   - Knowl-edgeGPTは、コード形式の知識ベースの検索クエリを生成し、事前定義されたKB操作関数を含みます。\n",
      "   - 提案されたDFA-RAGフレームワークは、トレーニングダイアログから学習されたDefinite Finite Automaton（DFA）をLLM内に統合し、会話エージェントの能力を向上させます。\n",
      "   - DFA-RAGは、人間が読み取れるDFAを通じて解釈可能な構造、応答のためのコンテキストに応じた検索、および既存のLLMとのプラグアンドプレイ互換性を提供します。\n",
      "\n",
      "2. **LLMオーケストレーションフレームワーク**:\n",
      "   - ドメイン固有のダイアログ生成に焦点を当てたタスク指向型ダイアログシステムは、インタラクティブなコミュニケーションを通じて特定のタスクを達成することを目指します。\n",
      "   - DFA-RAGフレームワークは、従来の勾配ベースのトレーニングを必要としない独自のアプローチを導入し、シンプルさと適応性を提供します。\n",
      "   - DFA-RAGは、現在のLLMアプリケーションの制約を解決し、カスタマーサービスなどの特定の領域で信頼性の高いコンテキストに適した応答を確保します。\n",
      "\n",
      "3. **エージェント関連の提案**:\n",
      "   - セマンティックルーターは、事前定義された意思決定レイヤーを備えたLLM技術の進展を表し、チャットボットやAIアシスタントを強化します。\n",
      "   - DFA-RAGはセマンティックルーターの進化と見なすことができ、直接の埋め込み比較ではなくタグを使用して意思決定を行うことで、解釈可能性と計算効率を向上させます。\n",
      "   - フレームワーク内のDFA構造は、過去のトレーニングデータから学習され、より適応性があり、実世界のアプリケーションにスケーラブルです。\n",
      "\n",
      "要約すると、RAG、LLMオーケストレーション、およびエージェントに関連する提案は、DFAの拡張、コンテキストに応じた検索、解釈可能な意思決定レイヤー、および歴史的トレーニングデータに基づく適応性を通じて、会話エージェントの能力を向上させることに焦点を当てています。これらのフレームワークは、特定のシナリオで規制された適合応答を生成する課題に取り組み、会話型AI技術の可能性の拡大を提供することを目指しています。\n",
      "\n",
      "Sources used:\n",
      "File: ./icml_2024_embeddings/PinNet: Pinpoint Instructive Information for Retrieval Augmented Code-to-Text Generation.csv\n",
      "File: ./icml_2024_embeddings/DFA-RAG: Conversational Semantic Router for Large Language Model with Definite Finite Automaton.csv\n"
     ]
    }
   ],
   "source": [
    "# 回答と共に使用したファイル名とテキストを表示\n",
    "print(f\"Response: {translated_response}\")\n",
    "print(\"\\nSources used:\")\n",
    "for file, text in zip(files, strings):\n",
    "    print(f\"File: {file}\")\n",
    "    # print(f\"Text: {text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818431be-b4a8-4e32-828b-b290dc253ba0",
   "metadata": {},
   "source": [
    "## 関連する文章自体の概要を出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25cfda52-17b5-448b-bd50-8a188a672b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"./icml_2024_papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36316334-2c83-4181-b0e4-251e5e9ecf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'./icml_2024_embeddings/DFA-RAG: Conversational Semantic Router for Large Language Model with Definite Finite Automaton.csv',\n",
       " './icml_2024_embeddings/PinNet: Pinpoint Instructive Information for Retrieval Augmented Code-to-Text Generation.csv'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 回答に使用したファイル\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda2cd88-d889-411d-90c9-cfd791f01de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFファイルのパスを生成\n",
    "pdf_paths = []\n",
    "for file in files:\n",
    "    file_name = os.path.basename(file)  # ファイル名を取得\n",
    "    pdf_file_name = os.path.splitext(file_name)[0] + \".pdf\"  # 拡張子を.csvから.pdfに変更\n",
    "    pdf_file_path = os.path.join(pdf_dir, pdf_file_name)  # PDFファイルのパスを生成\n",
    "    pdf_paths.append(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183a7499-b566-45d0-8b6c-fda601b2dff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./icml_2024_papers/PinNet: Pinpoint Instructive Information for Retrieval Augmented Code-to-Text Generation.pdf\n",
      "./icml_2024_papers/DFA-RAG: Conversational Semantic Router for Large Language Model with Definite Finite Automaton.pdf\n"
     ]
    }
   ],
   "source": [
    "# 結果を表示\n",
    "for pdf_path in pdf_paths:\n",
    "    print(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb1e09c-8879-4bf1-b067-15a3fe49692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFからテキストを抽出する関数\n",
    "def convert_pdf_to_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b16f76ca-06b0-4c7a-9fe4-3690ef007432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各PDFファイルのテキストを取得して表示\n",
    "pdf_texts = []\n",
    "for pdf_path in pdf_paths:\n",
    "    text = convert_pdf_to_text(pdf_path)\n",
    "    pdf_texts.append({'file': pdf_path, 'text': text})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df08694b-2622-43c7-b204-69b2b92292ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./icml_2024_papers/PinNet: Pinpoint Instructive Information for Retrieval Augmented Code-to-Text Generation.pdf\n",
      "Text: RankRAG: Unifying Context Ranking with\n",
      "Retrieval-Augmented Generation in LLMs\n",
      "Yue Yu∗\n",
      "Georgia TechWei Ping∗\n",
      "NVIDIAZihan Liu\n",
      "NVID...\n",
      "----------------------------------------------------------------\n",
      "File: ./icml_2024_papers/DFA-RAG: Conversational Semantic Router for Large Language Model with Definite Finite Automaton.pdf\n",
      "Text: DFA-RAG: Conversational Semantic Router for Large Language Model\n",
      "with Definite Finite Automaton\n",
      "Yiyou Sun1 2Junjie Hu1Wei Cheng2...\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# pdf取得結果のテスト表示\n",
    "for pdf in pdf_texts:\n",
    "    print(f\"File: {pdf['file']}\")\n",
    "    print(f\"Text: {pdf['text'][:128]}...\") \n",
    "    print(\"-\"*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f3167b-6d7a-426d-8cd3-1e3e02af56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wiki_outline(model_name, scientific_paper):\n",
    "    # Wikipediaページのアウトラインを生成する関数\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an experienced Wikipedia writer and want to edit a specific page.\"},\n",
    "        {\"role\": \"system\", \"content\": \"Your task is to write an outline of a Wikipedia page based on the content of a scientific article.\"},\n",
    "        {\"role\": \"system\", \"content\": \"Here is the format of your writing:\"},\n",
    "        {\"role\": \"system\", \"content\": \"1. Use '#' Title ' to indicate section title, '##' Title ' to indicate subsection title, '###' Title ' to indicate subsubsection title, and so on.\"},\n",
    "        {\"role\": \"system\", \"content\": \"2. Do not include other information.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Scientific Paper: {scientific_paper}\"},\n",
    "        {\"role\": \"system\", \"content\": \"Based on this information, please create a structured outline for the Wikipedia page.\"},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=prompt,\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    \n",
    "    outline = response.choices[0].message.content\n",
    "    \n",
    "    return outline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0550e0d9-dced-4791-8028-1d060ed957af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detailed_outline(model_name, outline, scientific_paper):\n",
    "    \"\"\"\n",
    "    Given a summary and related search results, enhance a Wikipedia page outline with detailed descriptions.\n",
    "    \n",
    "    Parameters:\n",
    "    model_name (str): The model to be used for generating the descriptions.\n",
    "    summary_text (str): Summary text providing a concise overview of the topic.\n",
    "    related_search_results (str): Text containing related search results or additional contextual information.\n",
    "    outline (str): The basic outline of the Wikipedia page.\n",
    "    \n",
    "    Returns:\n",
    "    str: The enhanced outline with detailed descriptions for each section.\n",
    "    \"\"\"\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are tasked with enhancing a Wikipedia page outline by integrating detailed descriptions based on a scientific article.\"},\n",
    "        {\"role\": \"system\", \"content\": \"Here is the basic outline of the page you need to expand with detailed explanations:\"},\n",
    "        {\"role\": \"user\", \"content\": outline},\n",
    "        {\"role\": \"system\", \"content\": \"Use the following scientific article.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Scientific Paper: {scientific_paper}\"},\n",
    "        {\"role\": \"system\", \"content\": \"Add a comprehensive description of each section based on the content of the scientific article, including an overview, an accurate description of the methodology, and relevant interpretations.\"}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=prompt,\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    \n",
    "    detailed_outline = response.choices[0].message.content\n",
    "    \n",
    "    return detailed_outline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "455a2861-fa77-4227-adf0-3a20f93635ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./icml_2024_papers/PinNet: Pinpoint Instructive Information for Retrieval Augmented Code-to-Text Generation.pdf\n",
      "# RankRAG：LLMでのコンテキストランキングと検索拡張生成の統合\n",
      "\n",
      "## 導入\n",
      "\n",
      "### 概要\n",
      "RankRAGフレームワークは、大規模言語モデル（LLMs）でコンテキストランキングと検索拡張生成（RAG）を統合することを目指しています。このアプローチは、コンテキストランキングメカニズムを統合することで、LLMsのコンテキストに即した回答を生成する能力を向上させます。この統合により、知識集約的なタスクにおいて特に、より正確でコンテクストに即した回答が得られるようになります。\n",
      "\n",
      "### 検索拡張生成（RAG）の背景\n",
      "検索拡張生成（RAG）は、検索メカニズムと生成モデルを組み合わせることで後者のパフォーマンスを向上させる手法です。検索コンポーネントは、外部コーパスから関連する文書やパッセージを選択し、生成モデルがこれを使用して回答を生成します。この方法は大規模データベースを活用し、最新かつ事実確実な情報を提供するため、生成モデルが高品質な出力を生成する能力が向上します。\n",
      "\n",
      "### RankRAGの動機\n",
      "RankRAGの動機は、既存のRAGモデルで観察される制限に起因します。これらのモデルは、コンテキストランキングでしばしば苦労することが多いです。多くのRAGモデルは、最も関連性の高い情報を効果的に優先付けできず、結果として最適でない回答生成となります。RankRAGは、この問題に対処するために、最も関連性の高いコンテキストが生成に使用されるようにする洗練されたランキングメカニズムを導入することで、回答の全体的な品質と正確性を向上させます。\n",
      "\n",
      "## 開発と実装\n",
      "\n",
      "### 著者と所属\n",
      "RankRAGフレームワークは、人工知能と機械学習に特化した一流機関の研究者チームによって開発されました。所属機関には、自然言語処理（NLP）の分野への貢献で知られる名門大学や研究所が含まれています。\n",
      "\n",
      "### 研究目標\n",
      "RankRAG研究の主な目標は、効果的なコンテキストランキングメカニズムを検索拡張生成と統合することによって、LLMsのパフォーマンスを向上させ、コンテクストに富んだ正確な回答を生成することです。研究者たちは、この統合がさまざまな知識集約的なタスクにおいて回答の品質を大幅に向上させることを示すことを目指しています。\n",
      "\n",
      "### 方法論\n",
      "\n",
      "#### インストラクションファインチューニングフレームワーク\n",
      "RankRAGモデルは、特定のインストラクションを使用してLLMsをトレーニングし、コンテキストランキングおよび回答生成タスクを実行するようにするインストラクションファインチューニングフレームワークを利用しています。このフレームワークにより、モデルは関連性の高いコンテキストを優先し、そのコンテキストに基づいて高品質な回答を生成することを学習します。\n",
      "\n",
      "#### コンテキストランキングと回答生成の二重目的\n",
      "RankRAGは、コンテキストランキングと回答生成の両方のタスクに同時に対処しています。コンテキストランキングコンポーネントは、コーパスから最も関連性の高い情報を選択し、生成コンポーネントはこのランク付けされた情報を使用して回答を生成します。この二重目的アプローチにより、生成された回答がコンテキストに即して正確であることが保証されます。\n",
      "\n",
      "#### トレーニングデータとアプローチ\n",
      "RankRAGのトレーニングデータには、オープンドメインの質問応答、事実検証、対話型QAなど、さまざまな知識集約的なタスク向けに設計された幅広いデータセットが含まれます。このアプローチは、事前トレーニングされたLLMsをこの多様なトレーニングデータでファインチューニングすることで、モデルがさまざまなクエリを処理し、高品質な回答を生成できるようにします。\n",
      "\n",
      "## RankRAGの特徴\n",
      "\n",
      "### ランキングと生成の統合\n",
      "RankRAGは、ランキングと生成をシームレスに統合し、常に最も関連性の高いコンテキストが回答生成に使用されるようにします。この統合は、広範なコーパスから最も関連性の高い情報を優先する洗練されたランキングメカニズムによって達成されます。\n",
      "\n",
      "### インストラクションチューニングされたLLMs\n",
      "RankRAGで使用されるLLMsは、インストラクションにチューニングされており、コンテキストランキングと回答生成のタスクを実行するための特定のインストラクションでトレーニングされています。このチューニングプロセスにより、モデルがこれらの二重目的に最適化されます。\n",
      "\n",
      "### コンテクストに富んだQA、検索拡張QA、およびランキングデータセット\n",
      "RankRAGは、コンテクストに富んだQA、検索拡張QA、ランキングタスク向けに設計されたさまざまなデータセットを活用しています。これらのデータセットは、LLMsをファインチューニングし、さまざまなタイプのクエリを処理し、高品質な回答を生成できるようにします。\n",
      "\n",
      "## パフォーマンス評価\n",
      "\n",
      "### 既存モデルとの比較\n",
      "\n",
      "#### GPT-4の変種\n",
      "RankRAGは、さまざまなGPT-4の変種と比較され、コンテクストに富んで正確な回答を生成する性能を評価します。比較の結果、RankRAGがいくつかの知識集約的なタスクでこれらの変種を凌駕していることが示されています。\n",
      "\n",
      "#### ChatQA-1.5\n",
      "RankRAGは、QAタスク向けに設計されたもう1つの最先端モデルであるChatQA-1.5と比較されます。比較の結果、RankRAGがより正確でコンテクストに即した回答を提供しています。\n",
      "\n",
      "#### 他のベースライン\n",
      "GPT-4の変種とChatQA-1.5に加えて、RankRAGは他のベースラインモデルとも比較され、その全体的なパフォーマンスが評価されます。結果は、RankRAGが高品質な回答を生成する点でこれらのベースラインを一貫して凌駕していることを示しています。\n",
      "\n",
      "### 知識集約的なベンチマーク\n",
      "\n",
      "#### 一般ドメインのベンチマーク\n",
      "RankRAGは、一般ドメインのベンチマークで評価され、幅広いクエリを処理する能力が評価されます。結果は、RankRAGが一般ドメインのタスクで正確でコンテクストに即した回答を生成する点で優れていることを示しています。\n",
      "\n",
      "#### バイオメディカルドメインのベンチマーク\n",
      "RankRAGは、バイオメディカルドメインのベンチマークでも評価され、ドメイン固有のクエリを処理する能力が評価されます。結果は、RankRAGがバイオメディカルドメインで正確でコンテクストに即した回答を生成する点で優れていることを示しています。\n",
      "\n",
      "## 実験設定\n",
      "\n",
      "### タスクとデータセット\n",
      "\n",
      "#### オープンドメインQA\n",
      "オープンドメインのQAタスクは、さまざまなトピックに基づいた質問に答えることを含みます。RankRAGは、オープンドメインQAのために特に設計されたデータセットでトレーニングおよび評価され、多様なクエリを処理する能力が評価されます。\n",
      "\n",
      "#### 事実検証\n",
      "事実検証タスクは、利用可能な証拠に基づいて文の正確性を検証することを含みます。RankRAGは、事実検証データセットでトレーニングおよび評価され、文の正確性を正確に検証する能力が評価されます。\n",
      "\n",
      "#### 対話型QA\n",
      "対話型QAタスクは、会話の文脈で回答を生成することを含みます。RankRAGは、対話型QAデータセットでトレーニングおよび評価され、コンテクストに即した一貫した回答を生成する能力が評価されます。\n",
      "\n",
      "### 実装の詳細\n",
      "\n",
      "#### トレーニングとファインチューニング\n",
      "RankRAGのトレーニングとファインチューニングプロセスは、さまざまな知識集約的なタスク向けに設計された多様なデータセットを使用して行われます。これらのデータセットでLLMsをファインチューニングすることで、モデルがさまざまなタイプのクエリを処理し、高品質な回答を生成できるようになります。\n",
      "\n",
      "#### 推論パイプライン\n",
      "RankRAGの推論パイプラインは、コンテキストランキングメカニズムを使用してコーパスから最も関連性の高い情報を選択し、そのランク付けされた情報をもとに回答を生成する生成コンポーネントを使用します。このパイプラインにより、生成された回答がコンテクストに即して正確であることが保証されます。\n",
      "\n",
      "## 結果と所見\n",
      "\n",
      "### 主な実験結果\n",
      "主な実験結果は、RankRAGが既存のモデルを常に凌駕し、コンテクストに富んで正確な回答を生成する点で著しい改善が見られることを示しています。オープンドメインQA、事実検証、対話型QAなどのさまざまな知識集約的なタスクで大幅な改善が見られます。\n",
      "\n",
      "### ドメイン固有のRAGベンチマーク\n",
      "\n",
      "#### Mirageベンチマークのパフォーマンス\n",
      "RankRAGは、Mirageベンチマークで評価され、検索拡張生成モデルのパフォーマンスを評価するために設計されたドメイン固有のRAGベンチマークで優れたパフォーマンスを発揮します。これにより、RankRAGが特定のドメインのタスクで高品質な回答を生成する能力が示されます。\n",
      "\n",
      "### 略奪研究\n",
      "\n",
      "#### 設計されたコンポーネントの効果\n",
      "略奪研究は、RankRAGのさまざまな設計されたコンポーネントの効果を評価するために実施されます。結果は、各コンポーネントがモデルの全体的なパフォーマンスに著しい貢献をしていることを示しています。\n",
      "\n",
      "#### 異なるLLMsでのパフォーマンス\n",
      "RankRAGのパフォーマンスは、異なるLLMsで評価され、その堅牢性と汎用性が評価されます。結果は、RankRAGがさまざまなLLMsでうまく機能し、その汎用性を示しています。\n",
      "\n",
      "#### 異なるリトリーバーでのパフォーマンス\n",
      "RankRAGのパフォーマンスは、異なるリトリーバーとも評価され、関連性の高いコンテキストを選択する能力が評価されます。結果は、RankRAGが常に最も関連性の高い情報を選択し、高品質な回答生成につながることを示しています。\n",
      "\n",
      "## 効率性と実用的な考慮事項\n",
      "\n",
      "### データ効率性\n",
      "RankRAGは、多様なデータセットを効果的に活用することでデータ効率性を実証しています。この効率性により、モデルがさまざまなタイプのクエリを処理し、データ要件を最小限に抑えて高品質な回答を生成できるようになります。\n",
      "\n",
      "### 時間効率性\n",
      "RankRAGは、回答を生成する際の時間効率性も実証しています。コンテキストランキングメカニズムにより、最も関連性の高い情報が迅速に特定され、正確でコンテクストに即した回答を生成するために必要な時間が短縮されます。\n",
      "\n",
      "###\n",
      "----------------------------------------------------------------\n",
      "File: ./icml_2024_papers/DFA-RAG: Conversational Semantic Router for Large Language Model with Definite Finite Automaton.pdf\n",
      "# DFA-RAG: 大規模言語モデル用の会話型意味ルーターと明確な有限オートマトン\n",
      "\n",
      "## はじめに\n",
      "通常、はじめにはDFA-RAGの概要を提供し、その目的を会話型AIを向上させるためのフレームワークとして強調します。これは、大規模言語モデル（LLMs）の柔軟性と構造化された信頼性の高いルールベースシステムの応答との間のギャップを埋めることに焦点を当てています。強調されているのは、Definite Finite Automaton（DFA）を活用して対話を規制し、応答のコンプライアンスと一貫性を確保することです。\n",
      "\n",
      "## 背景\n",
      "### 伝統的LLMsの課題\n",
      "伝統的なLLMsは強力ですが、しばしば関連性のない、不一致な、または特定のガイドラインに準拠しない応答を生成します。これらの問題は、広範で多様なデータから学習された確率的パターンに依存するモデルによって引き起こされ、重要なアプリケーションでの予測不可能性をもたらします。\n",
      "\n",
      "### ルールベースの対話システムとLLMs\n",
      "ルールベースシステムは一貫した予測可能な応答を提供する点で優れていますが、LLMsの柔軟性と適応性には欠けています。それに対して、LLMsは多様で動的な対話を処理できますが、構造化された相互作用を維持し、応答のコンプライアンスを確保するのに苦劦します。\n",
      "\n",
      "### 規制とコンプライアンス応答の重要性\n",
      "医療、金融、法務サービスなどのアプリケーションでは、対話システムが厳格な規制基準に準拠する応答を生成することが重要です。会話型AIにおけるコンプライアンスと規制の確保は、信頼性を向上させます。\n",
      "\n",
      "## DFA-RAGフレームワーク\n",
      "### 概要\n",
      "DFA-RAGフレームワークはDFAsとRAGの強みを組み合わせて堅牢な会話型AIシステムを作成します。DFAを使用して対話フローを導き、RAGを使用して関連情報を取得し、応答が文脈に適切でコンプライアンスが取れるようにします。\n",
      "\n",
      "### Definite Finite Automaton（DFA）\n",
      "#### 定義と構成要素\n",
      "DFAは、入力データ内のパターンを認識するために使用される理論的計算モデルです。それは状態、これらの状態間の遷移、および初期状態で構成されます。各遷移には特定の入力記号がラベル付けされています。\n",
      "\n",
      "#### 対話への応用\n",
      "会話型AIでは、DFAは対話の状態の許容されるシーケンスをモデル化し、会話が事前定義されたルールと構造に適合するようにします。これは、対話の一貫性とコンプライアンスの維持に役立ちます。\n",
      "\n",
      "### 情報取得増強生成（RAG）\n",
      "#### 戦略とメカニズム\n",
      "RAGは情報取得と応答生成を統合します。まず、ユーザーの入力に基づいて関連文書や情報を取得し、その情報をLLMの支援を受けて応答を生成します。\n",
      "\n",
      "#### DFAとの統合\n",
      "統合には、DFAを使用してRAGプロセスを制限し、情報取得と生成がDFAによって定義された構造化フローに適合することを保証します。この組み合わせにより、関連性とコンプライアンスの両方が向上します。\n",
      "\n",
      "## 方法論\n",
      "### 問題設定\n",
      "#### データ設定\n",
      "このセクションでは、DFA-RAGフレームワークのトレーニングおよび評価に使用されるデータセットについて、ソース、対話の種類、および前処理手順の詳細を説明します。\n",
      "\n",
      "#### ゴール\n",
      "主な目標は、DFAの構造化ガイダンスとRAGの柔軟性を利用して、文脈に即した適合性のある応答を生成する会話型AIシステムを開発することです。\n",
      "\n",
      "### DFAを使用した対話のモデリング\n",
      "#### DFAの基礎\n",
      "対話モデリングの文脈に合わせた、状態、遷移、受入条件などのDFA概念の紹介。\n",
      "\n",
      "#### タグシーケンスとしての対話\n",
      "ユーザーの発話は、対話内の異なる状態や意図を表す特定のラベルでタグ付けされ、DFAによってモデル化されるシーケンスを形成します。\n",
      "\n",
      "#### DFAとしての対話セット\n",
      "対話のセットはDFAを構築するために使用され、各ユニークなパスが対話状態の許容されるシーケンスを表します。\n",
      "\n",
      "### 対話からのDFAの学習\n",
      "#### LLMsを使用したタグシーケンスの抽出\n",
      "LLMsは、事前定義されたカテゴリや意図に基づいてユーザーの発話にタグ付けされ、タグシーケンスの構築を容易にします。\n",
      "\n",
      "#### タグシーケンスでのツリー構築\n",
      "タグシーケンスは、ルートから葉までの各パスが可能な対話フローを表すツリー構造に整理されます。\n",
      "\n",
      "#### タグツリーでの状態のマージ\n",
      "類似または冗長な状態をマージしてDFAを簡素化し、会話フローの基本的な構造を保ちながら複雑さを低減します。\n",
      "\n",
      "### DFA-RAGによる対話生成\n",
      "#### ユーザの発話へのタグ付け\n",
      "ユーザの入力は、対応する状態や意図にタグ付けされ、DFAをナビゲートします。\n",
      "\n",
      "#### DFAのナビゲーション\n",
      "システムは、タグ付けされた発話を使用してDFAを通過し、適切な応答パスを決定します。\n",
      "\n",
      "#### 対話IDへのアクセス\n",
      "特定の状態に関連付けられた対話IDは、関連情報や応答生成のためのテンプレートを取得するのに役立ちます。\n",
      "\n",
      "#### LLM用のプロンプトの編集\n",
      "プロンプトはLLM用に構築され、取得した情報を組み込み、DFAによってナビゲートされたフローと整合性を保ちます。\n",
      "\n",
      "#### LLM応答生成\n",
      "LLMは、編集されたプロンプトに基づいて応答を生成し、それらが関連性があり、コンプライアンスが取れることを確認します。\n",
      "\n",
      "#### 繰り返しプロセス\n",
      "会話は繰り返され、各ユーザの発話がタグ付けされ、DFAを通過し、適合性のある応答が生成されます。\n",
      "\n",
      "## 実験結果\n",
      "### データセット\n",
      "評価に使用されるデータセットの詳細について、特性、ソース、タスクへの関連性などが記載されています。\n",
      "\n",
      "### 生成品質評価\n",
      "#### 評価手法\n",
      "生成された応答の品質を評価するために使用される手法について、人間による評価、自動化されたメトリクス、またはタスク固有の基準などが含まれます。\n",
      "\n",
      "#### ベースライン\n",
      "DFA-RAGフレームワークの改善点と強みを強調するために、ベースライン手法との比較が行われます。\n",
      "\n",
      "#### 観察\n",
      "実験結果からの主な発見が示され、提案されたフレームワークの効果が示されます。\n",
      "\n",
      "### 対話タスクの評価\n",
      "#### 評価メトリクス\n",
      "対話タスクのパフォーマンスを評価するために使用されるメトリクスには、正確さ、関連性、コンプライアンスなどが含まれます。\n",
      "\n",
      "#### ベースライン手法との比較\n",
      "既存手法とのパフォーマンス比較が行われ、DFA-RAGの利点が強調されます。\n",
      "\n",
      "### 構築されたDFAのデモンストレーション\n",
      "会話データから構築されたDFAの例が示され、対話フローをどのように案内するかが説明されます。\n",
      "\n",
      "## 議論と今後の展望\n",
      "### 分布外発話の処理\n",
      "事前定義されたDFA構造外の入力を処理する戦略について、堅牢性と適応性を確保します。\n",
      "\n",
      "### 外部モジュールとの統合\n",
      "機能性と応用範囲を拡張するための他のシステムやモジュールとの潜在的な統合について。\n",
      "\n",
      "## 関連作業\n",
      "### 構造化対話システム\n",
      "既存の構造化対話システムおよびその制限事項のレビュー。\n",
      "\n",
      "### 情報取得増強生成（RAG）\n",
      "RAGアプローチの概要と、会話型AIでの適用について。\n",
      "\n",
      "### タスク指向型対話システム\n",
      "タスク指向型対話システムに関する議論とDFA-RAGへの関連性について。\n",
      "\n",
      "### 意味ルーター\n",
      "意味ルーターの概念の探求と、対話フローの案内における役割について。\n",
      "\n",
      "## 結論\n",
      "DFA-RAGフレームワークの主要な貢献、発見、および意義の要約であり、会話型AIへの潜在的な影響が強調されます。\n",
      "\n",
      "## 影響声明\n",
      "DFA-RAGの広範な影響に関する声明であり、倫理的考慮事項、潜在的な応用、および今後の方向について述べられます。\n",
      "\n",
      "## 謝辞\n",
      "個人、機関、資金提供源からの貢献とサポートに対する謝辞。\n",
      "\n",
      "## 参考文献\n",
      "記事全体で引用された包括的な参考文献リストであり、さらなる読書や文脈の提供のソースを提供しています。\n",
      "----------------------------------------------------------------\n",
      "CPU times: user 105 ms, sys: 558 μs, total: 105 ms\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pdf取得結果のテスト表示\n",
    "for pdf in pdf_texts:\n",
    "    print(f\"File: {pdf['file']}\")\n",
    "    outline_text = generate_wiki_outline(MODEL4o_NAME, pdf['text'])\n",
    "    # 生成したアウトラインに詳細な説明を加える\n",
    "    detailed_outline = generate_detailed_outline(MODEL4o_NAME, outline_text, outline_text)\n",
    "    \n",
    "    lang = detect(detailed_outline)\n",
    "    if lang != \"ja\":\n",
    "        translated_detailed_outline = translate_to_japanese(MODEL_NAME, detailed_outline)\n",
    "    else:\n",
    "        translated_detailed_outline = response\n",
    "    print(translated_detailed_outline)\n",
    "    print(\"-\"*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43c1a4-6a93-41dd-acb7-a4e5ece0fd68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
